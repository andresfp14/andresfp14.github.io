---
title: Explaining Neural Networks Through Concept Extraction
summary: This research project focuses on the methodological and application aspects of how to explain what a deep neural network learns through training. Specifically, this project tackles the development of methods for concept extraction, localization, and learning, as well as their applications in industrial scenarios.
tags:
  - Deep Learning
  - Data Science
  - eXplainable Artificial Intelligence
  - Concept Extraction
date: '2019-04-27T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: ''

#links:
#  - icon: 
#    icon_pack: fab
#    name: DFG
#    url: https://gepris.dfg.de/gepris/projekt/390621612?language=en
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
#slides: example
---

# Project Overview
This research project dedicated to unraveling the complexities of deep neural networks (DNNs) through the lens of explainable artificial intelligence (XAI), focusing specifically on the concept extraction process. This project addresses the critical need for transparency and understandability in DNNs, particularly in industrial applications where reliability and decision-making accuracy are paramount. The research centers on developing innovative methods for concept extraction, localization, and learning. These methodologies aim to clarify what DNNs learn during training, transforming the often opaque 'black box' of neural networks into a more interpretable and trustworthy system. This is especially relevant in scenarios where convolutional neural networks (CNNs) are employed for crucial tasks like industrial quality control, and understanding their decision-making process is vital for ensuring both safety and efficiency.

Key to this project is the creation of global explanations for trained neural network models through advanced concept extraction techniques. The research focuses into the development of novel algorithms like the Scale-Preserving Automatic Concept Extraction (SPACE) and Extracting Concepts with Local Aggregated Descriptors (ECLAD). These approaches are designed to not only identify but also accurately locate relevant concepts within images, a significant leap forward in understanding and validating CNNs' predictions. The application of these techniques in Industry 4.0 scenarios has demonstrated their efficacy in providing clear, actionable insights into the CNNs' decision mechanisms. The project showcases its utility across various industrial use cases, from material design and manufacturing to maintenance, proving that these advanced concept extraction methods can effectively bridge the gap between raw data processing and human-interpretable knowledge, thereby enhancing the credibility and applicability of machine learning in the industrial domain.

















